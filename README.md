# Requisitos atendidos nesse reposit√≥rio:
![requisitos-mat-aplicada-repo.png](docs/requisitos-mat-aplicada-repo.png)

# AutoML

Este projeto implementa um **notebook AutoML** capaz de receber **qualquer base de dados tabular** (CSV), realizar o pr√©-processamento adequado e testar automaticamente diferentes algoritmos de **Machine Learning**, escolhendo o melhor modelo de acordo com as m√©tricas de avalia√ß√£o.

---

## Funcionalidades

- Leitura de qualquer dataset `.csv`, identificando automaticamente o delimitador.  
- Tratamento de **dados faltantes** (substitui√ß√£o por moda/mais frequente).  
- Codifica√ß√£o de vari√°veis categ√≥ricas (`LabelEncoder`).  
- Normaliza√ß√£o de vari√°veis num√©ricas (`StandardScaler`).  
- Teste autom√°tico de **7 algoritmos de ML**:
- 2 algoritmos de regress√£o: 
  - Regress√£o Linear
  - KNN Regressor
- 5 Algoritmos de classifica√ß√£o:
  - Decision Tree (crit√©rio = `"gini"`)  
  - Decision Tree (crit√©rio = `"entropy"`)  
  - Naive Bayes  
  - KNN - Classifier
  - XGBoost - Classifier

- **Otimiza√ß√£o autom√°tica de hiperpar√¢metros** para cada modelo utilizando `GridSearchCV`.
<img width="260" alt="image" src="https://github.com/user-attachments/assets/081a2a41-8fce-4be0-9694-099fde92c116" />
  
## Sele√ß√£o do **melhor modelo** com base em m√©tricas de avalia√ß√£o.

### Classifica√ß√£o: 
- Acur√°cia

#### Exemplo
- KNN - 92% de acur√°cia
- Naive Bayes - 87% de acur√°cia
---
#### Campe√£o: KNN üèÜ
---

### Regress√£o:
- R¬≤

#### Exemplo
- Regress√£o Linear - 67% de R¬≤
- KNN Regressor - 87% de R¬≤

---
#### Campe√£o: KNN RegressorüèÜ
---

## Estrutura do Projeto

```
‚îú‚îÄ‚îÄ datasets/          # Datasets testados de exemplo
‚îî‚îÄ‚îÄ docs/              # Pasta com fotos dos gr√°ficos
‚îú‚îÄ‚îÄ pickles/           # Pasta com pickles (modelo_<nome>_<base>.pkl)
‚îú‚îÄ‚îÄ ia-preditiva.ipynb # Notebook principal
‚îú‚îÄ‚îÄ requirements.txt   # Requisitos para rodar o ambiente.
‚îî‚îÄ‚îÄ README.md          # Documenta√ß√£o sobre o notebook todo
```

---

### Depend√™ncias necess√°rias
- `jupyter`
- `nbconvert`
- `nbformat`
- `papermill`
- `pandas`
- `numpy`
- `matplotlib`
- `scikit-learn`
- `seaborn`
- `xgboost`
- `yellowbrick`

---

## Exemplo de Sa√≠da

### Classifica√ß√£o

- **Compara√ß√£o de Modelos (Acur√°cia):**
<img src="docs/comparacao_modelos_example.png" alt="" width="400"/>

- **Matriz de Confus√£o**:  
<img src="docs/matriz_confusao_example.png" alt="" width="400"/>


- **Compara√ß√£o de Classes (M√©tricas):**
<img src="docs/metricas_example.png" alt="" width="400"/>

### Regress√£o

- **Compara√ß√£o de Modelos (Regress√£o):**
<img src="docs/comparacao_modelos_r2_example.png" alt="" width="400"/>

- **Res√≠duos dos Modelos**:  
<img src="docs/residuos_example.png" alt="" width="400"/>

- **Distribui√ß√£o dos Res√≠duos**:
<img src="docs/distribuicao_residuos_example.png" alt="" width="400"/>



---

Desenvolvido por: [**Rafael Cruz**](https://github.com/RafaelBarretoCruz)
